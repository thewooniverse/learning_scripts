{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75a6bcee-b821-4b0e-9712-ced3f362bdb1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# LangChain Overview\n",
    "\n",
    "All code comes from [LangChain docs](langchain.readthedocs.io)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc576310-3ca1-48dc-b188-16377585fbf4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install langchain openai cohere huggingface_hub ipywidgets chromadb google-search-results Xformers tiktoken\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0469cafb-adab-48f7-9645-3447a2aa1cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import langchain\n",
    "from langchain.llms import OpenAI, Cohere\n",
    "from langchain import HuggingFacePipeline\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1140620-f6c2-47a2-b4ab-97bcca405c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"TYPE YOUR API KEY\"\n",
    "os.environ[\"COHERE_API_KEY\"] = \"TYPE YOUR API KEY\"\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"TYPE YOUR API KEY\"\n",
    "os.environ[\"SERPAPI_API_KEY\"] = \"TYPE YOUR API KEY\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a485e97f-81cd-441e-a574-eb08bdbb6d03",
   "metadata": {},
   "source": [
    "# LLMs\n",
    "\n",
    "Integration with many LLM providers\n",
    "- OpenAI\n",
    "- Cohere\n",
    "- AI21\n",
    "- Huggingface Hub\n",
    "- Azure OpenAI\n",
    "- Manifest\n",
    "- Goose AI\n",
    "- Writer\n",
    "- Banana\n",
    "- Modal\n",
    "- StochasticAI\n",
    "- Cerebrium\n",
    "- Petals\n",
    "- Forefront AI\n",
    "- PromptLayer OpenAI\n",
    "- Anthropic\n",
    "- DeepInfra\n",
    "- Self-Hosted Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba64897-6732-4441-80ed-36671e4b02d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatgpt = ChatOpenAI(model_name='gpt-3.5-turbo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9aa6934-44e3-4daa-b1ac-bcf61e6e2071",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt3 = OpenAI(model_name='text-davinci-003')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2b5e43-1020-4a42-80bb-30d3b30bcea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohere = Cohere(model='command-xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0684523-0a0b-4858-b44b-f5c04ecdaffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bloom = HuggingFacePipeline.from_model_id(model_id=\"bigscience/bloom-1b7\", task=\"text-generation\", model_kwargs={\"temperature\":0, \"max_length\":64})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec92bad-7ea6-4131-a342-5e1a6f48479d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"How to be happy?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76574d9-8815-4af3-b444-eb256a5fe0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatgpt([HumanMessage(content=text)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e09a2b-7b91-4edc-b6e1-8a0428098345",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gpt3(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e987a19-bfdf-4d60-849c-d8168b79a459",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cohere(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356725f5-d04a-45bc-b1c4-4c382477468b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(bloom(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6783cb2d-d3ca-426b-94cf-13e1eb966486",
   "metadata": {},
   "source": [
    "# Question Answering with external document\n",
    "\n",
    "There are a lot of document loaders:\n",
    "File Loader, Directory Loader, Notion, ReadTheDocs, HTML, PDF, PowerPoint, Email, GoogleDrive, Obsidian, Roam, EverNote, YouTube, Hacker News, GitBook, S3 File, S3 Directory, GCS File, GCS Directory, Web Base, IMSDb, AZLyrics, College Confidential, Gutenberg, Airbyte Json, CoNLL-U, iFixit, Notebook, Copypaste, CSV, Facebook Chat, Image, Markdown, SRT, Telegram, URL, Word Document, Blackboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cf6ce2-2411-4167-860b-e3c2214b5773",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "loader = TextLoader('state_of_the_union.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f8ce64-23be-4c8d-b78e-4444588b0850",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "index = VectorstoreIndexCreator().from_loaders([loader])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3b1fd9-c8ae-4072-b40d-bff6eabac0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What did the president say about Ketanji Brown Jackson\"\n",
    "index.query(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3513e651-7205-4457-a282-ffcd20ca513b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Keep memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5393cd9d-3dd0-4469-abf1-dc6d8a029929",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferWindowMemory, CombinedMemory, ConversationSummaryMemory\n",
    "\n",
    "\n",
    "conv_memory = ConversationBufferWindowMemory(\n",
    "    memory_key=\"chat_history_lines\",\n",
    "    input_key=\"input\",\n",
    "    k=1\n",
    ")\n",
    "\n",
    "summary_memory = ConversationSummaryMemory(llm=OpenAI(), input_key=\"input\")\n",
    "# Combined\n",
    "memory = CombinedMemory(memories=[conv_memory, summary_memory])\n",
    "_DEFAULT_TEMPLATE = \"\"\"The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
    "\n",
    "Summary of conversation:\n",
    "{history}\n",
    "Current conversation:\n",
    "{chat_history_lines}\n",
    "Human: {input}\n",
    "AI:\"\"\"\n",
    "PROMPT = PromptTemplate(\n",
    "    input_variables=[\"history\", \"input\", \"chat_history_lines\"], template=_DEFAULT_TEMPLATE\n",
    ")\n",
    "llm = OpenAI(temperature=0)\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    verbose=True, \n",
    "    memory=memory,\n",
    "    prompt=PROMPT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58ef99d-51a0-41e5-aa58-35517e097a0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conversation.run(\"Hi!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b03643-df85-4f7e-9580-910c77330eb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conversation.run(\"Can you tell me a joke?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c247979-2e7d-4953-a901-83eceeceecb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conversation.run(\"Can you tell me a similar joke?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a14d389-fc9d-4d01-85f7-5408073395f7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c973720b-4edc-4b39-92f4-98b9e4f3c6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain import LLMChain\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "human_message_prompt = HumanMessagePromptTemplate(\n",
    "        prompt=PromptTemplate(\n",
    "            template=\"What is a good name for a company that makes {product}?\",\n",
    "            input_variables=[\"product\"],\n",
    "        )\n",
    "    )\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages([human_message_prompt])\n",
    "chat = ChatOpenAI(temperature=0.9)\n",
    "chain = LLMChain(llm=chat, prompt=chat_prompt_template)\n",
    "print(chain.run(\"colorful socks\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271b35a4-8f56-4a2b-9c71-de91d67253b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_prompt = PromptTemplate(\n",
    "    input_variables=[\"company_name\"],\n",
    "    template=\"Write a catchphrase for the following company: {company_name}\",\n",
    ")\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ad82c8-5a1d-42e5-ad65-9fd7b5987976",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "overall_chain = SimpleSequentialChain(chains=[chain, chain_two], verbose=True)\n",
    "\n",
    "# Run the chain specifying only the input variable for the first chain.\n",
    "catchphrase = overall_chain.run(\"colorful socks\")\n",
    "print(catchphrase)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7203d1dd-607e-425e-a7ea-70e755e0084f",
   "metadata": {},
   "source": [
    "# Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a01df7c-34bd-44fe-83d5-5f3b8d3c2393",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "tools = load_tools([\"serpapi\", \"llm-math\"], llm=gpt3)\n",
    "agent = initialize_agent(tools, llm=gpt3, agent=\"zero-shot-react-description\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88efb8e9-b59e-4548-902c-6cdfe9825a92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent.run(\"Who is Leo DiCaprio's girlfriend? What is her current age raised to the 0.43 power?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7c90a4-88a1-401f-8ecd-6c6fa5184b5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tools = load_tools([\"serpapi\", \"python_repl\"], llm=gpt3)\n",
    "agent = initialize_agent(tools, llm=gpt3, agent=\"zero-shot-react-description\", verbose=True)\n",
    "agent.run(\"Who is Leo DiCaprio's girlfriend? What is her current age raised to the 0.49 power?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d89c95-c292-493b-9a44-f874ac86f441",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcb90d6-1bd5-440e-ab0b-c583b570b558",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
