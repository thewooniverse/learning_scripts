{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da089c2d-2d87-42af-9116-a86ac7a17399",
   "metadata": {},
   "source": [
    "# Prompt Engineering:\n",
    "\n",
    "What are Prompts? Prompts involve instructions and context passed to a language model to achieve a desired task\n",
    "\n",
    "Prompt engineering is the practice of developing and optimizing prompts to efficiently use language models (LMs or LLMs) for a variety of applications. This also applies to other models like image generation models such as DALL-E, stable diffisuion models.\n",
    "- Prompt engineering is a usefull skill for AI engineers and researchers to improve and efficiently use language models.\n",
    "\n",
    "---\n",
    "### Elements of a Prompt\n",
    "A prompt is composed with the following components:\n",
    "<img src=\"./prompt_elements.png\" \n",
    "     align=\"center\"\n",
    "     width=\"375\" />\n",
    "\n",
    "In the above example, we are asking the LM to classify a piece of text.\n",
    "\n",
    "---\n",
    "### Settings to keep in mind\n",
    "You can get very different results using a LM when using different settings. One important setting is controlling how deterministic the model is when generating completion for prompts:\n",
    "- Temperature and top_p are two important parameters to keep in mind\n",
    "- Generally, keep them low if you are looking for exact answers\n",
    "- Keep them high if you are looking for more diverse responses.\n",
    "\n",
    "---\n",
    "### Different types of prompts\n",
    "Some include Text Summarization, Question adn Answering, Text Classification, Role Playing, Code Generation, Reasoning etc...\n",
    "\n",
    "\n",
    "<img src=\"./classification_simple.png\" \n",
    "     align=\"center\"\n",
    "     width=\"375\" />\n",
    "\n",
    "\n",
    "Demo: https://github.com/dair-ai/Prompt-Engineering-Guide/blob/main/notebooks/pe-lecture.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "310802bc-6f2a-470b-9518-27cac878f600",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai_api_key=os.getenv('OPENAI_API_KEY', 'YourAPIKey')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f358bfc-73e6-4dc0-a12e-4095f016beb5",
   "metadata": {},
   "source": [
    "## Advanced Prompt engineering techniques;\n",
    "There are many advanced prompting techniques that are designed to improve performance on complex tasks such as:\n",
    "- Few Shot prompts\n",
    "- Chain-of-Thought prompting\n",
    "- Self-Consistency\n",
    "- Knowledge Generation Prompting\n",
    "- ReAct"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "22e15cd6-10a1-49a1-b7e5-909ab9bd94af",
   "metadata": {},
   "source": [
    "### Fewshot Prompt Templates\n",
    "Few shot prompt templates enables in-context learning for the model by giving it a few examples; basically providing examples / exemplars to steer the model towards a specfic better performance.\n",
    "\n",
    "More demonstration, the more it learns.\n",
    "\n",
    "---\n",
    "<center><img src=\"./fewshot.png\" \n",
    "     align=\"center\"\n",
    "     width=\"375\" /><center/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9675557b-bc85-4e71-bf6b-24faad93788c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FewShot practice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea88b0a-c429-4390-ac08-92e72f5180c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7869d8f7-5657-493a-8768-4d7326ccc8d7",
   "metadata": {},
   "source": [
    "### Chain-of-Thought (CoT) prompting\n",
    "\n",
    "Telling the model step by step the chain of thought in solving a specific exemplar; and asking for it to solve a similar question. As seen in highlighted example below, it shows the thought process.\n",
    "\n",
    "---\n",
    "<center><img src=\"./cot.png\" \n",
    "     align=\"center\"\n",
    "     width=\"375\" /><center/>\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "Interestingly, there has also been a paper where it suggests examples are not even necessary. prompt the model to think step by step -> and it induces model to think step by step and reason.\n",
    "\n",
    "<center><img src=\"./zs_cot.png\" \n",
    "     align=\"center\"\n",
    "     width=\"375\" /><center/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231334d5-8e04-4fba-85f9-0eefd7560c00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e136e1e2-d575-4d92-bf90-a75d1797656b",
   "metadata": {},
   "source": [
    "### Self-Consistency\n",
    "Language models alone are not great at complex reasoning tasks ; they are not designed to do this.\n",
    "There are prompt engineering solutions that help solve a lot of these like Self Consistency.\n",
    "Self consistency is basically to sample multiple diverse resasoning paths and use the generations to sleect the most consistent answer. **This helps boost the performance of CoT prompting on tasks involving arithmetic and common sense reasoning**\n",
    "\n",
    "<center><img src=\"./sc_cot.png\" \n",
    "     align=\"center\"\n",
    "     width=\"375\" /><center/>\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "<center><img src=\"./sc_example.png\" \n",
    "     align=\"center\"\n",
    "     width=\"375\" /><center/>\n",
    "\n",
    "---\n",
    "You can see from the above example how the model gets to the output in different ways, and that eventually the one that gets voted on top is 67 which is the correct answer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97d12ae-3bf2-4e64-938d-520f7ea8426d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "36bb4c88-7cfa-4d60-8ce0-80d317189156",
   "metadata": {},
   "source": [
    "### Knowledge Generation\n",
    "Using a model to generate knowledge that can be used to help sovle a problem / do a specific task.\n",
    "\n",
    "---\n",
    "\n",
    "<center><img src=\"./gkp1.png\" \n",
    "     align=\"center\"\n",
    "     width=\"550\" /><center/>\n",
    "\n",
    "---\n",
    "As seen in the example below, we should always steer the model in a certain way by giving a few examples or using a prompt template to steer the model in a certain way - to think in a certain type of way.\n",
    "\n",
    "\n",
    "<center><img src=\"./gkp2.png\" \n",
    "     align=\"center\"\n",
    "     width=\"550\" /><center/>\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "<center><img src=\"./gkp3.png\" \n",
    "     align=\"center\"\n",
    "     width=\"550\" /><center/>\n",
    "\n",
    "\n",
    "You can see from the above example on how the two different knowledge fed into the question generated different answers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94726af9-1383-41a3-a466-fc541e68cb26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7a6b7981-7b92-4f44-ac4d-df8bfdaa1522",
   "metadata": {},
   "source": [
    "### Program-aided Language Model\n",
    "Sometimes CoT is not good enough (CoT just uses text), PAL is thinking could the model answer the questions better if they used an external tool like a python interpreter.\n",
    "**Basically uses a language model to read problems and generate programs as the intermediate reasoning step**. In this case we are relying on an external tool;.\n",
    "\n",
    "---\n",
    "\n",
    "<center><img src=\"./PAL.png\" \n",
    "     align=\"center\"\n",
    "     width=\"375\" /><center/>\n",
    "\n",
    "---\n",
    "\n",
    "<center><img src=\"./PAL2.png\" \n",
    "     align=\"center\"\n",
    "     width=\"550\" /><center/>\n",
    "\n",
    "\n",
    "The instructions as seen in the example can be commented code as steps. Using the existing capabilities of the model + external tools -> solve harder problems.\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874e7c6c-16c8-4e10-957e-823c7521fa6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd267f24-233f-4f35-9c91-dd18c9960cbe",
   "metadata": {},
   "source": [
    "### ReAct\n",
    "ReAct == Reason + Act. Relying not only on capabilities of the model, but also relies on external sources and can take actions to basically get more information from external sources. \n",
    "\n",
    "Thought >> Action >> Observation >> Thought >>>>>\n",
    "\n",
    "---\n",
    "\n",
    "<center><img src=\"./ReAct.png\" \n",
    "     align=\"center\"\n",
    "     width=\"375\" /><center/>\n",
    "\n",
    "---\n",
    "\n",
    "<center><img src=\"./ReAct2.png\" \n",
    "     align=\"center\"\n",
    "     width=\"600\" /><center/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d8b06c-2413-40f1-bf04-75a2f0192a3e",
   "metadata": {},
   "source": [
    "### Other important concepts\n",
    "\n",
    "Tools + LLMs + Agents ==> Can build apps and systems to solve complex problems\n",
    "\n",
    "<center><img src=\"./LLM_Tools.png\" \n",
    "     align=\"center\"\n",
    "     width=\"600\" /><center/>\n",
    "\n",
    "---\n",
    "### DAG VS RAG\n",
    "Retrieval Augmented Generation (RAG) and Data Augmented Generation are both techniques used in the field of machine learning and artificial intelligence, but they serve different purposes and are used in different contexts.\n",
    "\n",
    "#### Retrieval Augmented Generation (RAG)\n",
    "\n",
    "1. **Concept**: RAG is a technique primarily used in natural language processing (NLP). It involves augmenting the process of generating text with an additional step of retrieving relevant information from a large dataset or corpus.\n",
    "\n",
    "2. **How It Works**: In RAG models, when generating a response or continuation, the system first retrieves relevant documents or snippets of text from a data source (like Wikipedia or a specialized database). Then, these retrieved texts are used alongside the input query to generate the final output.\n",
    "\n",
    "3. **Purpose**: The goal of RAG is to enhance the quality of the generated text by grounding it in real-world knowledge and information. It's particularly useful for tasks like question answering, where the model might need to pull in external information to accurately answer a question.\n",
    "\n",
    "4. **Examples**: Models like Facebook AI’s RAG or Google’s REALM.\n",
    "\n",
    "#### Data Augmented Generation\n",
    "\n",
    "1. **Concept**: Data Augmented Generation refers to techniques used to artificially expand or enhance a training dataset, especially in scenarios where data is scarce, imbalanced, or lacks diversity.\n",
    "\n",
    "2. **How It Works**: This involves creating new, synthetic data points from existing data through various transformations. For example, in image processing, this might include rotating, flipping, or adding noise to images. In text data, it could involve paraphrasing or creating new sentences.\n",
    "\n",
    "3. **Purpose**: The primary purpose is to improve the robustness and generalization ability of machine learning models. By training on more diverse data, models are less likely to overfit and perform better on unseen data.\n",
    "\n",
    "4. **Use Cases**: Common in fields like computer vision, speech recognition, and NLP.\n",
    "\n",
    "#### Key Differences\n",
    "\n",
    "- **Functionality**: RAG is about enhancing text generation by pulling in external information during the generation process. In contrast, Data Augmented Generation is about expanding the size and diversity of a dataset before training.\n",
    "  \n",
    "- **Usage in Model Lifecycle**: RAG is used during the model's operation (inference time), while Data Augmentation is a part of the preprocessing stage in the model's training pipeline.\n",
    "\n",
    "- **Objective**: RAG aims to make the generated output more accurate and informed by external knowledge, while Data Augmentation aims to make models more robust and less prone to overfitting.\n",
    "\n",
    "In summary, Retrieval Augmented Generation is a technique used during model inference to improve text generation quality by retrieving relevant information, whereas Data Augmented Generation is a preprocessing technique used to improve model training by creating a more diverse and extensive training dataset.\n",
    "\n",
    "<center><img src=\"./DAG.png\" \n",
    "     align=\"center\"\n",
    "     width=\"600\" /><center/>\n",
    "\n",
    "\n",
    "\n",
    "**Unlike RAG, DAG doesn't involve real-time retrieval of information; it's about enriching the training process to improve overall model robustness and generalization.**\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "<center><img src=\"./RLHF.png\" \n",
    "     align=\"center\"\n",
    "     width=\"600\" /><center/>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db35cd89-01af-442d-9b9f-13b58abd33f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc95da2-b680-4399-9e89-ff7f1f11a23d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a540660-eb15-4963-8487-1f51895dc9cd",
   "metadata": {},
   "source": [
    "# Practices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7eedc02f-2b07-47d0-8325-6ea304e9c78a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
